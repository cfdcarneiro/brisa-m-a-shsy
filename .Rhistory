Protocol.EXEMPLO = Protocol.EXEMPLO %>% rename(Protocol = X.U.FEFF.Protocol_ID)
EXEMPLO = full_join(Artigos.EXEMPLO, Figure_Table.EXEMPLO, by = "Article_ID")
EXEMPLO = EXEMPLO %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
EXEMPLO = full_join(EXEMPLO, Results.EXEMPLO, by = "Fig_ID")
EXEMPLO = full_join(EXEMPLO, Protocol.EXEMPLO, by = "Protocol")
EXEMPLO = EXEMPLO %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
EXEMPLO = EXEMPLO %>% select(-c("Article_ID", "Fig_ID", "Results_ID", "Protocol", "Date_results", "Date"))
dados_todos = bind_rows(dados_todos, EXEMPLO)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(readxl)
library(writexl)
Artigos.Adriano = read.csv("Article-Grid view Adriano.csv", encoding = "UTF-8")
Artigos.AnaPaula = read.csv("Article-Grid view Ana Paula.csv", encoding = "UTF-8")
Artigos.Antonio = read.csv("Article-Grid view Antonio.csv", encoding = "UTF-8")
Artigos.Clarissa = read.csv("Article-Grid view Clarissa.csv", encoding = "UTF-8")
Artigos.Giovanna = read.csv("Article-Grid view Giovanna.csv", encoding = "UTF-8")
Artigos.Giovanna = Artigos.Giovanna %>% select(-c("Fig_ID"))
Artigos.Giulia = read.csv("Article-Grid view Giulia.csv", encoding = "UTF-8")
Artigos.Glaucia = read.csv("Article-Grid view Glaucia.csv", encoding = "UTF-8")
Artigos.NathaliaF = read.csv("Article-Grid view Nathalia F.csv", encoding = "UTF-8")
Artigos.NathaliaP = read.csv("Article-Grid view Nathalia P.csv", encoding = "UTF-8")
Artigos.NathaliaP = Artigos.NathaliaP %>% select(-c("Fig_ID", "Results_ID..from.Result_ID."))
Artigos.Samantha = read.csv("Article-Grid view Samantha.csv", encoding = "UTF-8")
Figure_Table.Adriano = read.csv("Figure_Table-Grid view Adriano.csv", encoding = "UTF-8")
Figure_Table.AnaPaula = read.csv("Figure_Table-Grid view Ana Paula.csv", encoding = "UTF-8")
Figure_Table.Antonio = read.csv("Figure_Table-Grid view Antonio.csv", encoding = "UTF-8")
Figure_Table.Clarissa = read.csv("Figure_Table-Grid view Clarissa.csv", encoding = "UTF-8")
Figure_Table.Giovanna = read.csv("Figure_Table-Grid view Giovanna.csv", encoding = "UTF-8")
Figure_Table.Giulia = read.csv("Figure_Table-Grid view Giulia.csv", encoding = "UTF-8")
Figure_Table.Glaucia = read.csv("Figure_Table-Grid view Glaucia.csv", encoding = "UTF-8")
Figure_Table.NathaliaF = read.csv("Figure_Table-Grid view Nathalia F.csv", encoding = "UTF-8")
Figure_Table.NathaliaP = read.csv("Figure_Table-Grid view Nathalia P.csv", encoding = "UTF-8")
Figure_Table.Samantha = read.csv("Figure_Table-Grid view Samantha.csv", encoding = "UTF-8")
Results.Adriano = read.csv("Results-Grid view Adriano.csv", encoding = "UTF-8")
Results.AnaPaula = read.csv("Results-Grid view Ana Paula.csv", encoding = "UTF-8")
Results.Antonio = read.csv("Results-Grid view Antonio.csv", encoding = "UTF-8")
Results.Clarissa = read.csv("Results-Grid view Clarissa.csv", encoding = "UTF-8")
Results.Giovanna = read.csv("Results-Grid view Giovanna.csv", encoding = "UTF-8")
Results.Giulia = read.csv("Results-Grid view Giulia.csv", encoding = "UTF-8")
Results.Glaucia = read.csv("Results-Grid view Glaucia.csv", encoding = "UTF-8")
Results.NathaliaF = read.csv("Results-Grid view Nathalia F.csv", encoding = "UTF-8")
Results.NathaliaP = read.csv("Results-Grid view Nathalia P.csv", encoding = "UTF-8")
Results.Samantha = read.csv("Results-Grid view Samantha.csv", encoding = "UTF-8")
Protocol.Adriano = read.csv("Protocol-Grid view Adriano.csv", encoding = "UTF-8")
Protocol.AnaPaula = read.csv("Protocol-Grid view Ana Paula.csv", encoding = "UTF-8")
Protocol.Antonio = read.csv("Protocol-Grid view Antonio.csv", encoding = "UTF-8")
Protocol.Clarissa = read.csv("Protocol-Grid view Clarissa.csv", encoding = "UTF-8")
Protocol.Giovanna = read.csv("Protocol-Grid view Giovanna.csv", encoding = "UTF-8")
Protocol.Giulia = read.csv("Protocol-Grid view Giulia.csv", encoding = "UTF-8")
Protocol.Glaucia = read.csv("Protocol-Grid view Glaucia.csv", encoding = "UTF-8")
Protocol.NathaliaF = read.csv("Protocol-Grid view Nathalia F.csv", encoding = "UTF-8")
Protocol.NathaliaP = read.csv("Protocol-Grid view Nathalia P.csv", encoding = "UTF-8")
Protocol.Samantha = read.csv("Protocol-Grid view Samantha.csv", encoding = "UTF-8")
Artigos.Adriano = Artigos.Adriano %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.AnaPaula = Artigos.AnaPaula %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.Antonio = Artigos.Antonio %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.Clarissa = Artigos.Clarissa %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.Giovanna = Artigos.Giovanna %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.Giulia = Artigos.Giulia %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.Glaucia = Artigos.Glaucia %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.NathaliaF = Artigos.NathaliaF %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.NathaliaP = Artigos.NathaliaP %>% rename(Article_ID = X.U.FEFF.Article_ID)
Artigos.Samantha = Artigos.Samantha %>% rename(Article_ID = X.U.FEFF.Article_ID)
Figure_Table.Adriano = Figure_Table.Adriano %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.AnaPaula = Figure_Table.AnaPaula %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.Antonio = Figure_Table.Antonio %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.Clarissa = Figure_Table.Clarissa %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.Giovanna = Figure_Table.Giovanna %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.Giulia = Figure_Table.Giulia %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.Glaucia = Figure_Table.Glaucia %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.NathaliaF = Figure_Table.NathaliaF %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.NathaliaP = Figure_Table.NathaliaP %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Figure_Table.Samantha = Figure_Table.Samantha %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Results.Adriano = Results.Adriano %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.AnaPaula = Results.AnaPaula %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.Antonio = Results.Antonio %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.Clarissa = Results.Clarissa %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.Giovanna = Results.Giovanna %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.Giulia = Results.Giulia %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.Glaucia = Results.Glaucia %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.NathaliaF = Results.NathaliaF %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.NathaliaP = Results.NathaliaP %>% rename(Results_ID = X.U.FEFF.Results_ID)
Results.Samantha = Results.Samantha %>% rename(Results_ID = X.U.FEFF.Results_ID)
Protocol.Adriano = Protocol.Adriano %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.AnaPaula = Protocol.AnaPaula %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.Antonio = Protocol.Antonio %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.Clarissa = Protocol.Clarissa %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.Giovanna = Protocol.Giovanna %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.Giulia = Protocol.Giulia %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.Glaucia = Protocol.Glaucia %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.NathaliaF = Protocol.NathaliaF %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.NathaliaP = Protocol.NathaliaP %>% rename(Protocol = X.U.FEFF.Protocol_ID)
Protocol.Samantha = Protocol.Samantha %>% rename(Protocol = X.U.FEFF.Protocol_ID)
#Protocol.Adriano = Protocol.Adriano %>% rename(Protocol = Protocol_ID)
#Protocol.AnaPaula = Protocol.AnaPaula %>% rename(Protocol = Protocol_ID)
#Protocol.Antonio = Protocol.Antonio %>% rename(Protocol = Protocol_ID)
#Protocol.Clarissa = Protocol.Clarissa %>% rename(Protocol = Protocol_ID)
#Protocol.Giovanna = Protocol.Giovanna %>% rename(Protocol = Protocol_ID)
#Protocol.Giulia = Protocol.Giulia %>% rename(Protocol = Protocol_ID)
#Protocol.Glaucia = Protocol.Glaucia %>% rename(Protocol = Protocol_ID)
#Protocol.NathaliaF = Protocol.NathaliaF %>% rename(Protocol = Protocol_ID)
#Protocol.NathaliaP = Protocol.NathaliaP %>% rename(Protocol = Protocol_ID)
#Protocol.Samantha = Protocol.Samantha %>% rename(Protocol = Protocol_ID)
Adriano = full_join(Artigos.Adriano, Figure_Table.Adriano, by = "Article_ID")
Adriano = Adriano %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
Adriano = full_join(Adriano, Results.Adriano, by = "Fig_ID")
Adriano = full_join(Adriano, Protocol.Adriano, by = "Protocol")
Adriano = Adriano %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
AnaPaula = full_join(Artigos.AnaPaula, Figure_Table.AnaPaula, by = "Article_ID")
AnaPaula = AnaPaula %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
AnaPaula = full_join(AnaPaula, Results.AnaPaula, by = "Fig_ID")
AnaPaula = full_join(AnaPaula, Protocol.AnaPaula, by = "Protocol")
AnaPaula = AnaPaula %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
Antonio = full_join(Artigos.Antonio, Figure_Table.Antonio, by = "Article_ID")
Antonio = Antonio %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
Antonio = full_join(Antonio, Results.Antonio, by = "Fig_ID")
Antonio = full_join(Antonio, Protocol.Antonio, by = "Protocol")
Antonio = Antonio %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
Clarissa = full_join(Artigos.Clarissa, Figure_Table.Clarissa, by = "Article_ID")
Clarissa = Clarissa %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
Clarissa = full_join(Clarissa, Results.Clarissa, by = "Fig_ID")
Clarissa = full_join(Clarissa, Protocol.Clarissa, by = "Protocol")
Clarissa = Clarissa %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
Giovanna = full_join(Artigos.Giovanna, Figure_Table.Giovanna, by = "Article_ID")
Giovanna = Giovanna %>% select(-c("OBS.x", "OBS.y"))
Giovanna = full_join(Giovanna, Results.Giovanna, by = "Fig_ID")
Giovanna = full_join(Giovanna, Protocol.Giovanna, by = "Protocol")
Giovanna = Giovanna %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
Giulia = full_join(Artigos.Giulia, Figure_Table.Giulia, by = "Article_ID")
Giulia = Giulia %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
Giulia = full_join(Giulia, Results.Giulia, by = "Fig_ID")
Giulia = full_join(Giulia, Protocol.Giulia, by = "Protocol")
Giulia = Giulia %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
Glaucia = full_join(Artigos.Glaucia, Figure_Table.Glaucia, by = "Article_ID")
Glaucia = Glaucia %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
Glaucia = full_join(Glaucia, Results.Glaucia, by = "Fig_ID")
Glaucia = full_join(Glaucia, Protocol.Glaucia, by = "Protocol")
Glaucia = Glaucia %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
NathaliaF = full_join(Artigos.NathaliaF, Figure_Table.NathaliaF, by = "Article_ID")
NathaliaF = NathaliaF %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
NathaliaF = full_join(NathaliaF, Results.NathaliaF, by = "Fig_ID")
NathaliaF = full_join(NathaliaF, Protocol.NathaliaF, by = "Protocol")
NathaliaF = NathaliaF %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
NathaliaP = full_join(Artigos.NathaliaP, Figure_Table.NathaliaP, by = "Article_ID")
NathaliaP = NathaliaP %>% select(-c("OBS.x", "Result_ID.x", "OBS.y", "Result_ID.y"))
NathaliaP = full_join(NathaliaP, Results.NathaliaP, by = "Fig_ID")
NathaliaP = full_join(NathaliaP, Protocol.NathaliaP, by = "Protocol")
NathaliaP = NathaliaP %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
Samantha = full_join(Artigos.Samantha, Figure_Table.Samantha, by = "Article_ID")
Samantha = Samantha %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
Samantha = full_join(Samantha, Results.Samantha, by = "Fig_ID")
Samantha = full_join(Samantha, Protocol.Samantha, by = "Protocol")
Samantha = Samantha %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
dados_todos = bind_rows(Adriano, AnaPaula, Antonio, Clarissa, Giovanna, Giulia, Glaucia, NathaliaF, NathaliaP, Samantha)
dados_todos = dados_todos %>% select(-c("Article_ID", "Fig_ID", "Results_ID", "Protocol", "Date_results", "Date", "Results", "Article", "Field.15", "Field.16")) %>% filter(rayyan.key!="")
write_xlsx(dados_todos, "dados_todos.xlsx")
#apenas comparacoes que precisam de dados dos autores (media dos dois grupos, variacao no tratado, n dos dos grupos)
dados_incompletos = dados_todos %>% filter(control_mean==0|is.na(control_mean)|treated_mean==0|is.na(treated_mean)|control_n==0|is.na(control_n)|treated_n==0|is.na(treated_n)|treated_variation==0|is.na(treated_variation))
write_xlsx(dados_incompletos, "dados_incompletos_SEM_unclear_variation.xlsx")
#incluindo também "unclear variation"
dados_incompletos2 = dados_todos %>% filter(control_mean==0|is.na(control_mean)|treated_mean==0|is.na(treated_mean)|control_n==0|is.na(control_n)|treated_n==0|is.na(treated_n)|treated_variation==0|is.na(treated_variation)|variation=="Unclear"|is.na(variation))
write_xlsx(dados_incompletos2, "dados_incompletos_COM_unclear_variation.xlsx")
#incluindo também isoforma Abeta
dados_incompletos3 = dados_todos %>% filter(control_mean==0|is.na(control_mean)|treated_mean==0|is.na(treated_mean)|control_n==0|is.na(control_n)|treated_n==0|is.na(treated_n)|treated_variation==0|is.na(treated_variation)|variation=="Unclear"|is.na(variation)|Abeta_sequence=="Not informed"|is.na(Abeta_sequence)|Abeta_sequence=="not reported")
write_xlsx(dados_incompletos3, "dados_incompletos_COM_isoforma.xlsx")
Artigos.EXEMPLO = read.csv("Article-Grid view EXEMPLO.csv", encoding = "UTF-8")
Figure_Table.EXEMPLO = read.csv("Figure_Table-Grid view EXEMPLO.csv", encoding = "UTF-8")
Results.EXEMPLO = read.csv("Results-Grid view EXEMPLO.csv", encoding = "UTF-8")
Protocol.EXEMPLO = read.csv("Protocol-Grid view EXEMPLO.csv", encoding = "UTF-8")
Artigos.EXEMPLO = Artigos.EXEMPLO %>% rename(Article_ID = X.U.FEFF.Article_ID)
Figure_Table.EXEMPLO = Figure_Table.EXEMPLO %>% rename(Fig_ID = X.U.FEFF.Fig_ID)
Results.EXEMPLO = Results.EXEMPLO %>% rename(Results_ID = X.U.FEFF.Results_ID)
Protocol.EXEMPLO = Protocol.EXEMPLO %>% rename(Protocol = X.U.FEFF.Protocol_ID)
EXEMPLO = full_join(Artigos.EXEMPLO, Figure_Table.EXEMPLO, by = "Article_ID")
EXEMPLO = EXEMPLO %>% select(-c("OBS.x", "Results.x", "OBS.y", "Results.y"))
EXEMPLO = full_join(EXEMPLO, Results.EXEMPLO, by = "Fig_ID")
EXEMPLO = full_join(EXEMPLO, Protocol.EXEMPLO, by = "Protocol")
EXEMPLO = EXEMPLO %>% select(-c("Results_ID.y")) %>% rename(Results_ID = Results_ID.x)
EXEMPLO = EXEMPLO %>% select(-c("Article_ID", "Fig_ID", "Results_ID", "Protocol", "Date_results", "Date"))
dados_todos = bind_rows(dados_todos, EXEMPLO)
View(dados_todos)
write_xlsx(dados_todos, "dados_todos.xlsx")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(metafor)
library(metaviz)
library(glmulti)
#dados_limpos = read_xlsx("dados_todos_limpos.xlsx")
dados_limpos = read_xlsx("dados_todos.xlsx")
dados_completos = dados_limpos %>% filter(control_mean!=0&!is.na(control_mean)&treated_mean!=0&!is.na(treated_mean)&control_n!=0&!is.na(control_n)&treated_n!=0&!is.na(treated_n)&treated_variation!=0&!is.na(treated_variation))
View(dados_completos)
dados_completos = dados_completos %>% filter(Abeta_sequence!="Not informed") %>% filter(Abeta_sequence!="not reported") %>% filter(!is.na(Abeta_sequence))
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(metafor)
library(metaviz)
library(glmulti)
#dados_limpos = read_xlsx("dados_todos_limpos.xlsx")
dados_limpos = read_xlsx("dados_todos.xlsx")
dados_completos = dados_limpos %>% filter(control_mean!=0&!is.na(control_mean)&treated_mean!=0&!is.na(treated_mean)&control_n!=0&!is.na(control_n)&treated_n!=0&!is.na(treated_n)&treated_variation!=0&!is.na(treated_variation))
dados_completos = dados_completos %>% filter(Abeta_sequence!="Not informed") %>% filter(Abeta_sequence!="not reported") %>% filter(!is.na(Abeta_sequence))
dados_completos = dados_completos %>% mutate(control_sd =
if_else(condition = variation=="SD", true = control_variation, false = (control_variation*sqrt(control_n))))
dados_completos = dados_completos %>% mutate(treated_sd =
if_else(condition = variation=="SD", true = treated_variation, false = (treated_variation*sqrt(treated_n))))
dados_two_sample = dados_completos %>% filter(!is.na(control_sd)) %>% filter(control_sd!=0)
dados_one_sample = dados_completos %>% filter(is.na(control_sd)|control_sd==0)
dados_two_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(control_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_two_sample)
dados_one_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(treated_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_one_sample)
dados_meta_smd = rbind(dados_two_sample_smd, dados_one_sample_smd)
dados_meta_smd = dados_meta_smd %>% mutate(Comparison.ID = 1:nrow(dados_meta_smd))
meta1 = rma(yi=yi, vi=vi, data = dados_meta_smd, measure = "SMD", method = "REML", slab = rayyan.key)
summary(meta1)
confint(meta1)
summary(dados_meta_smd$control_n)
summary(dados_meta_smd$treated_n)
summary(dados_meta_smd$vi)
top.vi = dados_meta_smd %>% arrange(-vi) %>% select(c("vi")) %>% slice(1:10)
kable(top.vi)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(metafor)
library(metaviz)
library(glmulti)
library(knitr)
#dados_limpos = read_xlsx("dados_todos_limpos.xlsx")
dados_limpos = read_xlsx("dados_todos.xlsx")
dados_completos = dados_limpos %>% filter(control_mean!=0&!is.na(control_mean)&treated_mean!=0&!is.na(treated_mean)&control_n!=0&!is.na(control_n)&treated_n!=0&!is.na(treated_n)&treated_variation!=0&!is.na(treated_variation))
dados_completos = dados_completos %>% filter(Abeta_sequence!="Not informed") %>% filter(Abeta_sequence!="not reported") %>% filter(!is.na(Abeta_sequence))
dados_completos = dados_completos %>% mutate(control_sd =
if_else(condition = variation=="SD", true = control_variation, false = (control_variation*sqrt(control_n))))
dados_completos = dados_completos %>% mutate(treated_sd =
if_else(condition = variation=="SD", true = treated_variation, false = (treated_variation*sqrt(treated_n))))
dados_two_sample = dados_completos %>% filter(!is.na(control_sd)) %>% filter(control_sd!=0)
dados_one_sample = dados_completos %>% filter(is.na(control_sd)|control_sd==0)
dados_two_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(control_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_two_sample)
dados_one_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(treated_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_one_sample)
dados_meta_smd = rbind(dados_two_sample_smd, dados_one_sample_smd)
dados_meta_smd = dados_meta_smd %>% mutate(Comparison.ID = 1:nrow(dados_meta_smd))
meta1 = rma(yi=yi, vi=vi, data = dados_meta_smd, measure = "SMD", method = "REML", slab = rayyan.key)
summary(meta1)
confint(meta1)
summary(dados_meta_smd$control_n)
summary(dados_meta_smd$treated_n)
summary(dados_meta_smd$vi)
top.vi = dados_meta_smd %>% arrange(-vi) %>% select(c("vi")) %>% slice(1:10)
kable(top.vi)
bottom.vi = dados_meta_smd %>% arrange(vi) %>% select(c("vi")) %>% slice(1:10)
kable(bottom.vi)
dados_meta_smd = dados_meta_smd %>% filter(vi<1000)
forest1 = viz_forest(meta1, study_labels = dados_meta_smd$rayyan.key, col = "black", annotate_CI = TRUE, xlab = "Hedge's g")
forest1
ggsave("forest.png", width = 10, height = 49, units = "in")
dados_meta_smd = dados_meta_smd %>% mutate(Comparison.ID = 1:nrow(dados_meta_smd))
meta_3l = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison.ID)
meta_3l
#confint(meta_3l)
#As there is not function in the package metafor for estimating I^2 values for 3-level models, we imported the function from Mathias Harrer & David Daniel Ebert (https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/mlm.variance.distribution.R)
mlm.variance.distribution = var.comp = function(x){
m = x
# Check class
if (!(class(m)[1] %in% c("rma.mv", "rma"))){
stop("x must be of class 'rma.mv'.")
}
# Check for three level model
if (m$sigma2s != 2){
stop("The model you provided does not seem to be a three-level model. This function can only be used for three-level models.")
}
# Check for right specification (nested model)
if (sum(grepl("/", as.character(m$random[[1]]))) < 1){
stop("Model must contain nested random effects. Did you use the '~ 1 | cluster/effect-within-cluster' notation in 'random'? See ?metafor::rma.mv for more details.")
}
# Get variance diagonal and calculate total variance
n = m$k.eff
vector.inv.var = 1/(diag(m$V))
sum.inv.var = sum(vector.inv.var)
sum.sq.inv.var = (sum.inv.var)^2
vector.inv.var.sq = 1/(diag(m$V)^2)
sum.inv.var.sq = sum(vector.inv.var.sq)
num = (n-1)*sum.inv.var
den = sum.sq.inv.var - sum.inv.var.sq
est.samp.var = num/den
# Calculate variance proportions
level1=((est.samp.var)/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
level2=((m$sigma2[2])/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
level3=((m$sigma2[1])/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
# Prepare df for return
Level=c("Level 1", "Level 2 (exp)", "Level 3 (art)")
Variance=c(level1, level2, level3)
df.res=data.frame(Variance)
colnames(df.res) = c("% of total variance")
rownames(df.res) = Level
I2 = c("---", round(Variance[2:3], 2))
df.res = as.data.frame(cbind(df.res, I2))
totalI2 = Variance[2] + Variance[3]
# Generate plot
df1 = data.frame("Level" = c("Sampling Error", "Total Heterogeneity"),
"Variance" = c(df.res[1,1], df.res[2,1]+df.res[3,1]),
"Type" = rep(1,2))
df2 = data.frame("Level" = rownames(df.res),
"Variance" = df.res[,1],
"Type" = rep(2,3))
df = as.data.frame(rbind(df1, df2))
g = ggplot(df, aes(fill=Level, y=Variance, x=as.factor(Type))) +
coord_cartesian(ylim = c(0,1), clip = "off") +
geom_bar(stat="identity", position="fill", width = 1, color="black") +
scale_y_continuous(labels = scales::percent)+
theme(axis.title.x=element_blank(),
axis.text.y = element_text(color="black"),
axis.line.y = element_blank(),
axis.title.y=element_blank(),
axis.line.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.y = element_line(lineend = "round"),
legend.position = "none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
legend.background = element_rect(linetype="solid",
colour ="black"),
legend.title = element_blank(),
legend.key.size = unit(0.75,"cm"),
axis.ticks.length=unit(.25, "cm"),
plot.margin = unit(c(1,3,1,1), "lines")) +
scale_fill_manual(values = c("darkseagreen3", "deepskyblue3", "darkseagreen2",
"deepskyblue1", "deepskyblue2")) +
# Add Annotation
# Total Variance
annotate("text", x = 1.5, y = 1.05,
label = paste("Total Variance:",
round(m$sigma2[1]+m$sigma2[2]+est.samp.var, 3))) +
# Sampling Error
annotate("text", x = 1, y = (df[1,2]/2+df[2,2])/100,
label = paste("Sampling Error Variance: \n", round(est.samp.var, 3)), size = 3) +
# Total I2
annotate("text", x = 1, y = ((df[2,2])/100)/2-0.02,
label = bquote("Total"~italic(I)^2*":"~.(round(df[2,2],2))*"%"), size = 3) +
annotate("text", x = 1, y = ((df[2,2])/100)/2+0.05,
label = paste("Variance not attributable \n to sampling error: \n", round(m$sigma2[1]+m$sigma2[2],3)), size = 3) +
# Level 1
annotate("text", x = 2, y = (df[1,2]/2+df[2,2])/100, label = paste("Level 1: \n",
round(df$Variance[3],2), "%", sep=""), size = 3) +
# Level 2
annotate("text", x = 2, y = (df[5,2]+(df[4,2]/2))/100,
label = bquote(italic(I)[Level2]^2*":"~.(round(df[4,2],2))*"%"), size = 3) +
# Level 3
annotate("text", x = 2, y = (df[5,2]/2)/100,
label = bquote(italic(I)[Level3]^2*":"~.(round(df[5,2],2))*"%"), size = 3)
returnlist = list(results = df.res,
totalI2 = totalI2,
plot = g)
class(returnlist) = c("mlm.variance.distribution", "list")
invisible(returnlist)
returnlist
}
mlm.variance.distribution(x = meta_3l)
#meta_trimfill_R = trimfill(meta, estimator = "R0", side = "right")
#meta_trimfill_R
#meta_trimfill_L = trimfill(meta, estimator = "L0", side = "right")
#meta_trimfill_L
#viz_funnel(x = meta_3l, trim_and_fill = TRUE, trim_and_fill_side = "right", xlab = "Hedge's g", y_axis = "se", ylab = "S.E.", contours = TRUE, sig_contours = FALSE, contours_type = "REM", egger = TRUE) + theme_classic()
#regtest(meta_3l)
meta_differentiation = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison.ID, mods = ~relevel(factor(dados_meta_smd$Diferentiation_method), ref="No differentiation"))
meta_differentiation
ggplot(dados_meta_smd, aes(x = Diferentiation_method, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Differentiation method") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey")
meta_difduration = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison.ID, mods = ~dados_meta_smd$Diferentiation_duration_days)
meta_difduration
ggplot(dados_meta_smd, aes(x = Diferentiation_duration_days, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Duration of differentiation (days)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(n.breaks = 7) +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
meta_aggregation = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison.ID, mods = ~relevel(factor(dados_meta_smd$Abeta_aggregation), ref="Unclear"))
meta_aggregation
ggplot(dados_meta_smd, aes(x = Abeta_aggregation, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Abeta aggregation") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey")
dados_meta_smd_max2500 = dados_meta_smd %>% filter(Concentration_uM<2500)
meta_concent = rma.mv(yi=yi, V=vi, data = dados_meta_smd_max2500, method = "REML", random = ~1|rayyan.key/Comparison.ID, mods = ~dados_meta_smd_max2500$Concentration_uM)
meta_concent
ggplot(dados_meta_smd_max2500, aes(x = Concentration_uM, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Abeta concentration (uM)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(n.breaks = 7) +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
meta_duration = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison.ID, mods = ~dados_meta_smd$Duration_hours)
meta_duration
ggplot(dados_meta_smd, aes(x = Duration_hours, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Abeta duration of exposure (hours)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(n.breaks = 7) +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
meta_assay = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison.ID, mods = ~relevel(factor(dados_meta_smd$Assay), ref="MTT"))
meta_assay
ggplot(dados_meta_smd, aes(x = Assay, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Assay") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey")
rma.mv.glmulti <- function(formula, data, ...)
rma.mv(formula, vi, data=data, method="ML", random = ~1|rayyan.key/Comparison.ID, verbose = FALSE, ...)
# Gera a lista de combinaÃ§Ãµes de preditores, a partir da lista de preditores e um de interesse, pra qual vocÃª quer calcular o R2 - retorna o texto das fÃ³rmulas, e.g. "~ a + b"
build_model_combinations = function (todos_preditores, preditor_interesse){
outros_preditores = todos_preditores[todos_preditores != preditor_interesse]
reduced_models = c("", map(1:length(outros_preditores), function (i) {
# Aqui Ã© onde as combinaÃ§Ãµes sÃ£o montadas de fato
paste0("~ ", apply(combn(outros_preditores, i), MARGIN = 2, paste0, collapse = " + "))
}) |> unlist())
# full model Ã© sÃ³ adicionar a variÃ¡vel de interesse
full_models = map_chr(reduced_models, function (f) {
if (f == "") {
return (paste0("~ ", preditor_interesse) )
} else {
return (paste0(f, " + ", preditor_interesse) )
}
})
list(full_models = full_models, reduced_models = reduced_models)
}
# Roda todos os modelos, par a par, full x reduced, a partir das fÃ³rmulas, e faz a diferença de R2
all_model_comparisons_3a = function (comparison_list) {
map2_dfr(comparison_list$reduced_models, comparison_list$full_models, function (m0s, m1s) {
if (m0s == "") {
# Se nÃ£o tem preditor, Ã© o modelo sem moderadores
m0 = rma(yi, vi, data=dat, method="ML", control = list(maxiter = 3000))
} else {
# Se tem preditores, usa a fÃ³rmula que vem da outra funÃ§Ã£o
m0f = as.formula(m0s)
m0 = rma.mv(yi, vi, random = ~1|rayyan.key/Comparison.ID, mods = m0f, data=dat, method="ML", control = list(maxiter = 3000))
}
m1f = as.formula(m1s)
m1 = rma.mv(yi, vi, random = ~1|rayyan.key/Comparison.ID, mods = m1f, data=dat, method="ML", control = list(maxiter = 3000))
m2 = rma.mv(yi=yi, V=vi, data = dat, method = "REML", random = ~1|rayyan.key/Comparison.ID, control = list(maxiter = 3000))
reduced_model_size = length(all.vars(m1f)) - 1
tibble(reduced = m0s, full = m1s, R2 = ((sum(m2$sigma2)-sum(m1$sigma2))/sum(m2$sigma2)*100)-((sum(m2$sigma2)-sum(m0$sigma2))/sum(m2$sigma2)*100), permutations = factorial(reduced_model_size))
})
}
# Faz todo o processo pra um Ãºnico preditor e resume na mÃ©dia dos R2
get_R2_for_single_predictor_3a = function (todos_preditores, preditor_interesse) {
comparison_list = build_model_combinations(todos_preditores, preditor_interesse)
r = all_model_comparisons_3a(comparison_list)
s = mean(r$R2, na.rm = T)
# Pra essa, o peso Ã© o nÃºmero de permutaÃ§Ãµes do modelo reduzido (se a variÃ¡vel de interesse Ã© 4a, tem 3! maneiras possÃ­veis dela ser a 4a, porque tem 3 variÃ¡veis antes dela pra permutar ... faz sentido?)
ws = weighted.mean(r$R2, r$permutations, na.rm = T)
list(all_predictors = todos_preditores, predictor = preditor_interesse, results = r, mean = s, wmean = ws)
}
# Faz todo o processo em separado pra cada um dos preditores da lista
get_R2_for_all_predictors_3a = function (todos_preditores) {
df = map(todos_preditores, function (preditor_interesse) {
print(paste("Running models for", preditor_interesse))
get_R2_for_single_predictor_3a(todos_preditores, preditor_interesse)
})
s = tibble(mean_R2 = map_dbl(df, "mean"), weighted_mean_R2 = map_dbl(df, "wmean"), predictor = map_chr(df, "predictor"))
list(full_results = df, summary = s)
}
dados_uteis <- dados_meta_smd
dados_uteis <-  dados_uteis[!apply(dados_uteis[,c("Diferentiation_method", "Abeta_aggregation", "Assay", "Diferentiation_duration_days", "Concentration_uM", "Duration_hours")], 1, anyNA),]
multi_meta_reg <- glmulti(yi ~ Diferentiation_method + Abeta_aggregation + Assay + Diferentiation_duration_days + Concentration_uM + Duration_hours, data = dados_uteis, level=1, fitfunction=rma.mv.glmulti, crit="aicc", confsetsize=(2^6), plotty = F)
print(multi_meta_reg)
dat = dados_uteis
meus_preditores = c("Diferentiation_duration_days", "Duration_hours")
melhor_modelo = get_R2_for_all_predictors_3a(meus_preditores)
melhor_modelo.summary = melhor_modelo$summary
melhor_modelo.summary = melhor_modelo.summary %>% mutate(pvalor=0)
melhor_modelo.summary[1,4] = anova(multi_meta_reg@objects[[1]], btt = 2)$QMp
melhor_modelo.summary[2,4] = anova(multi_meta_reg@objects[[1]], btt = 3)$QMp
multi_meta_reg@objects[[1]]
melhor_modelo.summary %>% select(1,3,4)
dados_uteis <- dados_meta_smd_max2500
dados_uteis <-  dados_uteis[!apply(dados_uteis[,c("Diferentiation_method", "Abeta_aggregation", "Assay", "Diferentiation_duration_days", "Concentration_uM", "Duration_hours")], 1, anyNA),]
multi_meta_reg <- glmulti(yi ~ Diferentiation_method + Abeta_aggregation + Assay + Diferentiation_duration_days + Concentration_uM + Duration_hours, data = dados_uteis, level=1, fitfunction=rma.mv.glmulti, crit="aicc", confsetsize=(2^6), plotty = F)
print(multi_meta_reg)
dat = dados_uteis
meus_preditores = c("Diferentiation_duration_days", "Duration_hours")
melhor_modelo = get_R2_for_all_predictors_3a(meus_preditores)
melhor_modelo.summary = melhor_modelo$summary
melhor_modelo.summary = melhor_modelo.summary %>% mutate(pvalor=0)
melhor_modelo.summary[1,4] = anova(multi_meta_reg@objects[[1]], btt = 2)$QMp
melhor_modelo.summary[2,4] = anova(multi_meta_reg@objects[[1]], btt = 3)$QMp
multi_meta_reg@objects[[1]]
melhor_modelo.summary %>% select(1,3,4)
