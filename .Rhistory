if_else(is.na(treated_variation_double_check)==T, true = treated_variation_original, false = treated_variation_double_check))
dados_completos = dados_completos %>% mutate(control_sd =
if_else(condition = variation=="SD", true = control_variation, false = (control_variation*sqrt(control_n))))
dados_completos = dados_completos %>% mutate(treated_sd =
if_else(condition = variation=="SD", true = treated_variation, false = (treated_variation*sqrt(treated_n))))
dados_two_sample = dados_completos %>% filter(!is.na(control_sd)) %>% filter(control_sd!=0)
dados_one_sample = dados_completos %>% filter(is.na(control_sd)|control_sd==0)
dados_two_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(control_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_two_sample)
dados_one_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(treated_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_one_sample)
dados_meta_smd = rbind(dados_two_sample_smd, dados_one_sample_smd)
dados_meta_smd = dados_meta_smd %>% mutate(Comparison_ID = 1:nrow(dados_meta_smd))
meta1 = rma(yi=yi, vi=vi, data = dados_meta_smd, measure = "SMD", method = "REML", slab = rayyan.key)
summary(meta1)
confint(meta1)
knitr::opts_chunk$set(echo = F)
library(readxl)
library(tidyverse)
library(metafor)
library(metaviz)
library(glmulti)
library(knitr)
dados_limpos = read_xlsx("dados_limpos.xlsx")
dados_completos = dados_limpos %>% filter(control_mean!=0&!is.na(control_mean)&treated_mean!=0&!is.na(treated_mean)&control_n!=0&!is.na(control_n)&treated_n!=0&!is.na(treated_n)&treated_variation!=0&!is.na(treated_variation))
dados_completos[dados_completos=="WST-1"] = "WST"
dados_completos[dados_completos=="WST-8"] = "WST"
dados_completos$Duration_hours = as.numeric(dados_completos$Duration_hours)
dados_completos = dados_completos %>% rename(control_mean_original = control_mean) %>%
rename(treated_mean_original = treated_mean) %>%
rename(control_variation_original = control_variation) %>%
rename(treated_variation_original = treated_variation)
dados_completos = dados_completos %>% mutate(control_mean =
if_else(is.na(control_mean_double_check)==T, true = control_mean_original, false = control_mean_double_check))
dados_completos = dados_completos %>% mutate(treated_mean =
if_else(is.na(treated_mean_double_check)==T, true = treated_mean_original, false = treated_mean_double_check))
dados_completos = dados_completos %>% mutate(control_variation =
if_else(is.na(control_variation_double_check)==T, true = control_variation_original, false = control_variation_double_check))
dados_completos = dados_completos %>% mutate(treated_variation =
if_else(is.na(treated_variation_double_check)==T, true = treated_variation_original, false = treated_variation_double_check))
dados_completos = dados_completos %>% mutate(control_sd =
if_else(condition = variation=="SD", true = control_variation, false = (control_variation*sqrt(control_n))))
dados_completos = dados_completos %>% mutate(treated_sd =
if_else(condition = variation=="SD", true = treated_variation, false = (treated_variation*sqrt(treated_n))))
dados_two_sample = dados_completos %>% filter(!is.na(control_sd)) %>% filter(control_sd!=0)
dados_one_sample = dados_completos %>% filter(is.na(control_sd)|control_sd==0)
dados_two_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(control_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_two_sample)
dados_one_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(treated_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_one_sample)
dados_meta_smd = rbind(dados_two_sample_smd, dados_one_sample_smd)
dados_meta_smd = dados_meta_smd %>% mutate(Comparison_ID = 1:nrow(dados_meta_smd))
meta1 = rma(yi=yi, vi=vi, data = dados_meta_smd, measure = "SMD", method = "REML", slab = rayyan.key)
summary(meta1)
confint(meta1)
#forest1 = viz_forest(meta1, study_labels = dados_meta_smd$rayyan.key, col = "black", annotate_CI = TRUE, xlab = "Hedge's g")
#forest1
#ggsave("forest.png", width = 10, height = 49, units = "in")
#dados_meta_smd = dados_meta_smd %>% mutate(Comparison_ID = 1:nrow(dados_meta_smd))
meta_3l = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID)
meta_3l
confint(meta_3l)
knitr::opts_chunk$set(echo = F)
library(readxl)
library(tidyverse)
library(metafor)
library(metaviz)
library(glmulti)
library(knitr)
dados_limpos = read_xlsx("dados_limpos.xlsx")
dados_completos = dados_limpos %>% filter(control_mean!=0&!is.na(control_mean)&treated_mean!=0&!is.na(treated_mean)&control_n!=0&!is.na(control_n)&treated_n!=0&!is.na(treated_n)&treated_variation!=0&!is.na(treated_variation))
dados_completos[dados_completos=="WST-1"] = "WST"
dados_completos[dados_completos=="WST-8"] = "WST"
dados_completos$Duration_hours = as.numeric(dados_completos$Duration_hours)
dados_completos = dados_completos %>% rename(control_mean_original = control_mean) %>%
rename(treated_mean_original = treated_mean) %>%
rename(control_variation_original = control_variation) %>%
rename(treated_variation_original = treated_variation)
dados_completos = dados_completos %>% mutate(control_mean =
if_else(is.na(control_mean_double_check)==T, true = control_mean_original, false = control_mean_double_check))
dados_completos = dados_completos %>% mutate(treated_mean =
if_else(is.na(treated_mean_double_check)==T, true = treated_mean_original, false = treated_mean_double_check))
dados_completos = dados_completos %>% mutate(control_variation =
if_else(is.na(control_variation_double_check)==T, true = control_variation_original, false = control_variation_double_check))
dados_completos = dados_completos %>% mutate(treated_variation =
if_else(is.na(treated_variation_double_check)==T, true = treated_variation_original, false = treated_variation_double_check))
dados_completos = dados_completos %>% mutate(control_sd =
if_else(condition = variation=="SD", true = control_variation, false = (control_variation*sqrt(control_n))))
dados_completos = dados_completos %>% mutate(treated_sd =
if_else(condition = variation=="SD", true = treated_variation, false = (treated_variation*sqrt(treated_n))))
dados_two_sample = dados_completos %>% filter(!is.na(control_sd)) %>% filter(control_sd!=0)
dados_one_sample = dados_completos %>% filter(is.na(control_sd)|control_sd==0)
dados_two_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(control_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_two_sample)
dados_one_sample_smd = escalc(measure = "SMD", m1i = as.numeric(treated_mean), m2i = as.numeric(control_mean), sd1i = as.numeric(treated_sd), sd2i = as.numeric(treated_sd), n1i = as.numeric(treated_n), n2i = as.numeric(control_n), data = dados_one_sample)
dados_meta_smd = rbind(dados_two_sample_smd, dados_one_sample_smd)
dados_meta_smd = dados_meta_smd %>% mutate(Comparison_ID = 1:nrow(dados_meta_smd))
meta1 = rma(yi=yi, vi=vi, data = dados_meta_smd, measure = "SMD", method = "REML", slab = rayyan.key)
summary(meta1)
confint(meta1)
#forest1 = viz_forest(meta1, study_labels = dados_meta_smd$rayyan.key, col = "black", annotate_CI = TRUE, xlab = "Hedge's g")
#forest1
#ggsave("forest.png", width = 10, height = 49, units = "in")
#dados_meta_smd = dados_meta_smd %>% mutate(Comparison_ID = 1:nrow(dados_meta_smd))
meta_3l = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID)
meta_3l
#confint(meta_3l)
#As there is not function in the package metafor for estimating I^2 values for 3-level models, we imported the function from Mathias Harrer & David Daniel Ebert (https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/mlm.variance.distribution.R)
mlm.variance.distribution = var.comp = function(x){
m = x
# Check class
if (!(class(m)[1] %in% c("rma.mv", "rma"))){
stop("x must be of class 'rma.mv'.")
}
# Check for three level model
if (m$sigma2s != 2){
stop("The model you provided does not seem to be a three-level model. This function can only be used for three-level models.")
}
# Check for right specification (nested model)
if (sum(grepl("/", as.character(m$random[[1]]))) < 1){
stop("Model must contain nested random effects. Did you use the '~ 1 | cluster/effect-within-cluster' notation in 'random'? See ?metafor::rma.mv for more details.")
}
# Get variance diagonal and calculate total variance
n = m$k.eff
vector.inv.var = 1/(diag(m$V))
sum.inv.var = sum(vector.inv.var)
sum.sq.inv.var = (sum.inv.var)^2
vector.inv.var.sq = 1/(diag(m$V)^2)
sum.inv.var.sq = sum(vector.inv.var.sq)
num = (n-1)*sum.inv.var
den = sum.sq.inv.var - sum.inv.var.sq
est.samp.var = num/den
# Calculate variance proportions
level1=((est.samp.var)/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
level2=((m$sigma2[2])/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
level3=((m$sigma2[1])/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
# Prepare df for return
Level=c("Level 1", "Level 2 (exp)", "Level 3 (art)")
Variance=c(level1, level2, level3)
df.res=data.frame(Variance)
colnames(df.res) = c("% of total variance")
rownames(df.res) = Level
I2 = c("---", round(Variance[2:3], 2))
df.res = as.data.frame(cbind(df.res, I2))
totalI2 = Variance[2] + Variance[3]
# Generate plot
df1 = data.frame("Level" = c("Sampling Error", "Total Heterogeneity"),
"Variance" = c(df.res[1,1], df.res[2,1]+df.res[3,1]),
"Type" = rep(1,2))
df2 = data.frame("Level" = rownames(df.res),
"Variance" = df.res[,1],
"Type" = rep(2,3))
df = as.data.frame(rbind(df1, df2))
g = ggplot(df, aes(fill=Level, y=Variance, x=as.factor(Type))) +
coord_cartesian(ylim = c(0,1), clip = "off") +
geom_bar(stat="identity", position="fill", width = 1, color="black") +
scale_y_continuous(labels = scales::percent)+
theme(axis.title.x=element_blank(),
axis.text.y = element_text(color="black"),
axis.line.y = element_blank(),
axis.title.y=element_blank(),
axis.line.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.y = element_line(lineend = "round"),
legend.position = "none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
legend.background = element_rect(linetype="solid",
colour ="black"),
legend.title = element_blank(),
legend.key.size = unit(0.75,"cm"),
axis.ticks.length=unit(.25, "cm"),
plot.margin = unit(c(1,3,1,1), "lines")) +
scale_fill_manual(values = c("darkseagreen3", "deepskyblue3", "darkseagreen2",
"deepskyblue1", "deepskyblue2")) +
# Add Annotation
# Total Variance
annotate("text", x = 1.5, y = 1.05,
label = paste("Total Variance:",
round(m$sigma2[1]+m$sigma2[2]+est.samp.var, 3))) +
# Sampling Error
annotate("text", x = 1, y = (df[1,2]/2+df[2,2])/100,
label = paste("Sampling Error Variance: \n", round(est.samp.var, 3)), size = 3) +
# Total I2
annotate("text", x = 1, y = ((df[2,2])/100)/2-0.02,
label = bquote("Total"~italic(I)^2*":"~.(round(df[2,2],2))*"%"), size = 3) +
annotate("text", x = 1, y = ((df[2,2])/100)/2+0.05,
label = paste("Variance not attributable \n to sampling error: \n", round(m$sigma2[1]+m$sigma2[2],3)), size = 3) +
# Level 1
annotate("text", x = 2, y = (df[1,2]/2+df[2,2])/100, label = paste("Level 1: \n",
round(df$Variance[3],2), "%", sep=""), size = 3) +
# Level 2
annotate("text", x = 2, y = (df[5,2]+(df[4,2]/2))/100,
label = bquote(italic(I)[Level2]^2*":"~.(round(df[4,2],2))*"%"), size = 3) +
# Level 3
annotate("text", x = 2, y = (df[5,2]/2)/100,
label = bquote(italic(I)[Level3]^2*":"~.(round(df[5,2],2))*"%"), size = 3)
returnlist = list(results = df.res,
totalI2 = totalI2,
plot = g)
class(returnlist) = c("mlm.variance.distribution", "list")
invisible(returnlist)
returnlist
}
mlm.variance.distribution(x = meta_3l)
dados_meta_smd %>% count(n_definition)
dados_meta_smd_independent = dados_meta_smd %>% filter(n_definition=="independent determinations" |
n_definition=="independent experimental measurements" |
n_definition=="independent experiments" |
n_definition=="independent repetitions" |
n_definition=="independent replicates" |
n_definition=="independent sets of studies")
meta_3l_independent = rma.mv(yi=yi, V=vi, data = dados_meta_smd_independent, method = "REML", random = ~1|rayyan.key/Comparison_ID)
meta_3l_independent
#confint(meta_3l_independent)
mlm.variance.distribution(x = meta_3l_independent)
#meta_trimfill_R = trimfill(meta, estimator = "R0", side = "right")
#meta_trimfill_R
#meta_trimfill_L = trimfill(meta, estimator = "L0", side = "right")
#meta_trimfill_L
#viz_funnel(x = meta_3l, trim_and_fill = TRUE, trim_and_fill_side = "right", xlab = "Hedge's g", y_axis = "se", ylab = "S.E.", contours = TRUE, sig_contours = FALSE, contours_type = "REM", egger = TRUE) + theme_classic()
dados_meta_smd = dados_meta_smd %>% mutate(mean_n = (treated_n+control_n)/2)
ggplot(dados_meta_smd, aes(x = yi, y = 1/sqrt(mean_n))) +
geom_point() +
scale_x_continuous(limits = c(-150,150), name = "Effect size (Hedge's g)") +
scale_y_continuous(trans = "reverse", name = expression(1/sqrt(N))) +
theme_classic() +
geom_vline(xintercept = 0, linetype="dashed", color = "grey") +
geom_vline(xintercept = meta1$beta, linetype="dashed", color = "darkgreen")
#ggsave("funnel-plot.png")
regtest(x = meta1, ni = dados_meta_smd$mean_n, predictor = "sqrtninv")
meta_differentiation = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~relevel(factor(dados_meta_smd$Diferentiation_method), ref="No differentiation"))
meta_differentiation
ggplot(dados_meta_smd, aes(x = Diferentiation_method, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Differentiation method") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey")
meta_difduration = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~dados_meta_smd$Diferentiation_duration_days)
meta_difduration
ggplot(dados_meta_smd, aes(x = as.numeric(Diferentiation_duration_days), y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Duration of differentiation (days)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(n.breaks = 7) +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
meta_aggregation = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~relevel(factor(dados_meta_smd$Abeta_aggregation), ref="Unclear"))
meta_aggregation
ggplot(dados_meta_smd, aes(x = Abeta_aggregation, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Abeta aggregation") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey")
dados_meta_smd_max2500 = dados_meta_smd %>% filter(Concentration_uM<2500)
meta_concent = rma.mv(yi=yi, V=vi, data = dados_meta_smd_max2500, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~dados_meta_smd_max2500$Concentration_uM)
meta_concent
ggplot(dados_meta_smd_max2500, aes(x = Concentration_uM, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Abeta concentration (uM)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(n.breaks = 7) +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
meta_duration = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~as.numeric(dados_meta_smd$Duration_hours))
meta_duration
ggplot(dados_meta_smd, aes(x = as.numeric(Duration_hours), y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Abeta duration of exposure (hours)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(n.breaks = 7) +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
meta_assay = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~relevel(factor(dados_meta_smd$Assay), ref="MTT"))
meta_assay
ggplot(dados_meta_smd, aes(x = Assay, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Assay") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey")
meta_density = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~as.numeric(dados_meta_smd$Cell_density))
meta_density
ggplot(dados_meta_smd, aes(x = as.numeric(Cell_density), y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, stroke = 1) +
labs(y = "Hedge's g", x = "Cell density (log10 scale)") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
scale_x_continuous(trans = "log10") +
geom_abline(slope = 0, linetype = "dashed", color = "grey")
rma.mv.glmulti <- function(formula, data, ...)
rma.mv(formula, vi, data=data, method="ML", random = ~1|rayyan.key/Comparison_ID, verbose = FALSE, ...)
# Gera a lista de combinaÃ§Ãµes de preditores, a partir da lista de preditores e um de interesse, pra qual vocÃª quer calcular o R2 - retorna o texto das fÃ³rmulas, e.g. "~ a + b"
build_model_combinations = function (todos_preditores, preditor_interesse){
outros_preditores = todos_preditores[todos_preditores != preditor_interesse]
reduced_models = c("", map(1:length(outros_preditores), function (i) {
# Aqui Ã© onde as combinaÃ§Ãµes sÃ£o montadas de fato
paste0("~ ", apply(combn(outros_preditores, i), MARGIN = 2, paste0, collapse = " + "))
}) |> unlist())
# full model Ã© sÃ³ adicionar a variÃ¡vel de interesse
full_models = map_chr(reduced_models, function (f) {
if (f == "") {
return (paste0("~ ", preditor_interesse) )
} else {
return (paste0(f, " + ", preditor_interesse) )
}
})
list(full_models = full_models, reduced_models = reduced_models)
}
# Roda todos os modelos, par a par, full x reduced, a partir das fÃ³rmulas, e faz a diferença de R2
all_model_comparisons_3a = function (comparison_list) {
map2_dfr(comparison_list$reduced_models, comparison_list$full_models, function (m0s, m1s) {
if (m0s == "") {
# Se nÃ£o tem preditor, Ã© o modelo sem moderadores
m0 = rma(yi, vi, data=dat, method="ML", control = list(maxiter = 3000))
} else {
# Se tem preditores, usa a fÃ³rmula que vem da outra funÃ§Ã£o
m0f = as.formula(m0s)
m0 = rma.mv(yi, vi, random = ~1|rayyan.key/Comparison_ID, mods = m0f, data=dat, method="ML", control = list(maxiter = 3000))
}
m1f = as.formula(m1s)
m1 = rma.mv(yi, vi, random = ~1|rayyan.key/Comparison_ID, mods = m1f, data=dat, method="ML", control = list(maxiter = 3000))
m2 = rma.mv(yi=yi, V=vi, data = dat, method = "REML", random = ~1|rayyan.key/Comparison_ID, control = list(maxiter = 3000))
reduced_model_size = length(all.vars(m1f)) - 1
tibble(reduced = m0s, full = m1s, R2 = ((sum(m2$sigma2)-sum(m1$sigma2))/sum(m2$sigma2)*100)-((sum(m2$sigma2)-sum(m0$sigma2))/sum(m2$sigma2)*100), permutations = factorial(reduced_model_size))
})
}
# Faz todo o processo pra um Ãºnico preditor e resume na mÃ©dia dos R2
get_R2_for_single_predictor_3a = function (todos_preditores, preditor_interesse) {
comparison_list = build_model_combinations(todos_preditores, preditor_interesse)
r = all_model_comparisons_3a(comparison_list)
s = mean(r$R2, na.rm = T)
# Pra essa, o peso Ã© o nÃºmero de permutaÃ§Ãµes do modelo reduzido (se a variÃ¡vel de interesse Ã© 4a, tem 3! maneiras possÃ­veis dela ser a 4a, porque tem 3 variÃ¡veis antes dela pra permutar ... faz sentido?)
ws = weighted.mean(r$R2, r$permutations, na.rm = T)
list(all_predictors = todos_preditores, predictor = preditor_interesse, results = r, mean = s, wmean = ws)
}
# Faz todo o processo em separado pra cada um dos preditores da lista
get_R2_for_all_predictors_3a = function (todos_preditores) {
df = map(todos_preditores, function (preditor_interesse) {
print(paste("Running models for", preditor_interesse))
get_R2_for_single_predictor_3a(todos_preditores, preditor_interesse)
})
s = tibble(mean_R2 = map_dbl(df, "mean"), weighted_mean_R2 = map_dbl(df, "wmean"), predictor = map_chr(df, "predictor"))
list(full_results = df, summary = s)
}
dados_uteis <- dados_meta_smd
dados_uteis <-  dados_uteis[!apply(dados_uteis[,c("Diferentiation_method", "Abeta_aggregation", "Assay", "Diferentiation_duration_days", "Concentration_uM", "Duration_hours", "Cell_density")], 1, anyNA),]
multi_meta_reg <- glmulti(yi ~ Diferentiation_method + Abeta_aggregation + Assay + Diferentiation_duration_days + Concentration_uM + Duration_hours + Cell_density, data = dados_uteis, level=1, fitfunction=rma.mv.glmulti, crit="aicc", confsetsize=(2^7), plotty = F)
print(multi_meta_reg)
dat = dados_uteis
meus_preditores = c("Diferentiation_duration_days", "Concentration_uM", "Duration_hours", "Cell_density")
melhor_modelo = get_R2_for_all_predictors_3a(meus_preditores)
melhor_modelo.summary = melhor_modelo$summary
#revisar!!!
#melhor_modelo.summary = melhor_modelo.summary %>% mutate(pvalor=0)
#melhor_modelo.summary[1,4] = anova(multi_meta_reg@objects[[1]], btt = 2)$QMp
#melhor_modelo.summary[2,4] = anova(multi_meta_reg@objects[[1]], btt = 3)$QMp
#multi_meta_reg@objects[[1]]
#melhor_modelo.summary %>% select(1,3,4)
#dados_uteis <- dados_meta_smd_max2500
#dados_uteis <-  dados_uteis[!apply(dados_uteis[,c("Diferentiation_method", "Abeta_aggregation", "Assay", "Diferentiation_duration_days", "Concentration_uM", "Duration_hours")], 1, anyNA),]
#multi_meta_reg <- glmulti(yi ~ Diferentiation_method + Abeta_aggregation + Assay + Diferentiation_duration_days + Concentration_uM + Duration_hours, data = dados_uteis, level=1, fitfunction=rma.mv.glmulti, crit="aicc", confsetsize=(2^6), plotty = F)
#print(multi_meta_reg)
#dat = dados_uteis
#meus_preditores = c("Diferentiation_duration_days", "Duration_hours")
#melhor_modelo = get_R2_for_all_predictors_3a(meus_preditores)
#melhor_modelo.summary = melhor_modelo$summary
#melhor_modelo.summary = melhor_modelo.summary %>% mutate(pvalor=0)
#melhor_modelo.summary[1,4] = anova(multi_meta_reg@objects[[1]], btt = 2)$QMp
#melhor_modelo.summary[2,4] = anova(multi_meta_reg@objects[[1]], btt = 3)$QMp
#multi_meta_reg@objects[[1]]
#melhor_modelo.summary %>% select(1,3,4)
dados_meta_smd %>% count(Created.By)
meta_revisor = rma.mv(yi=yi, V=vi, data = dados_meta_smd, method = "REML", random = ~1|rayyan.key/Comparison_ID, mods = ~relevel(factor(dados_meta_smd$Created.By), ref = "Adriano Sebollela"))
meta_revisor
ggplot(dados_meta_smd, aes(x = Created.By, y=yi, size = 1/sqrt(vi))) +
geom_point(shape = 1, position =  position_jitterdodge(dodge.width = 0), stroke = 1) +
labs(y = "Hedge's g", x = "Revisor") +
theme_classic() +
scale_size_continuous(guide = "none") +
theme(legend.position = "bottom") +
scale_y_continuous(n.breaks = 7) +
geom_abline(yintercept = 0, slope = 0, linetype = "dashed", color = "grey") +
scale_x_discrete(guide = guide_axis(angle = 45))
dados_por_artigo = dados_completos %>% distinct(rayyan.key, .keep_all = T)
ggplot(dados_por_artigo, aes(x=year)) +
geom_histogram(binwidth = 1, color="black", fill = "white") +
theme_classic() +
scale_y_continuous(limits = c(0,50), n.breaks = 10)
reversal = dados_por_artigo %>% count(tests_reversal)
ssc = dados_por_artigo %>% count(sample_size_calculation)
conflict = dados_por_artigo %>% count(conflict_interest)
registration = dados_por_artigo %>% count(protocol_registration)
article_level = data.frame(
Feature=c("Studies testing reversal",
"Provides sample size calculation",
"Includes conflict of interest statement",
"Has pre-registered"),
Count = c(as.numeric(reversal[2,2]),
0,
as.numeric(conflict[1,2]+conflict[3,2]),
as.numeric(registration[2,2]+registration[3,2])),
Percent = c(as.numeric(reversal[2,2])*100/nrow(dados_por_artigo),
0*100/nrow(dados_por_artigo),
as.numeric(conflict[1,2]+conflict[3,2])*100/nrow(dados_por_artigo),
as.numeric(registration[2,2]+registration[3,2])*100/nrow(dados_por_artigo))
)
kable(article_level, digits = 1)
assay = dados_completos %>% count(Assay)
kable(assay %>% arrange(-n), digits = 1)
csource = dados_completos %>% count(Cell_source)
kable(csource %>% arrange(-n), digits = 1)
cbank = dados_completos %>% filter(Cell_source=="Cell bank") %>% count(Cell_bank)
kable(cbank %>% arrange(-n), digits = 1)
cauthent = dados_completos %>% count(Cell_authentication)
kable(cauthent %>% arrange(-n), digits = 1)
cmyco = dados_completos %>% count(Cell_mycoplasma)
kable(cmyco %>% arrange(-n), digits = 1)
cserum = dados_completos %>% count(Serum_type)
kable(cserum %>% arrange(-n), digits = 1)
cserumconc = dados_completos %>% count(Serum_concentration)
kable(cserumconc %>% arrange(-n), digits = 1)
#adicionar meio de cultura e suplementos
control = dados_completos %>% count(Control_description)
kable(control %>% arrange(-n), digits = 1)
a_seq = dados_completos %>% count(Abeta_sequence)
kable(a_seq %>% arrange(-n), digits = 1)
a_orig = dados_completos %>% count(Abeta_origin)
kable(a_orig %>% arrange(-n), digits = 1)
a_spec = dados_completos %>% count(Abeta_species)
kable(a_spec %>% arrange(-n), digits = 1)
a_aggr = dados_completos %>% count(Abeta_aggregation)
kable(a_aggr %>% arrange(-n), digits = 1)
a_exp = dados_completos %>% count(Single_exposure)
kable(a_exp %>% arrange(-n), digits = 1)
dados_completos %>% summarise(mean(Duration_hours, na.rm = T))
dados_completos %>% summarise(sd(Duration_hours, na.rm = T))
dados_completos %>% summarise(median(Duration_hours, na.rm = T))
dados_completos %>% summarise(min(Duration_hours, na.rm = T))
dados_completos %>% summarise(max(Duration_hours, na.rm = T))
ggplot(dados_completos, aes(x=Duration_hours)) +
geom_histogram(binwidth = 1, color="black", fill = "white") +
theme_classic() +
scale_y_continuous(n.breaks = 10) +
scale_x_continuous(n.breaks = 10)
dados_completos %>% summarise(mean(Concentration_uM, na.rm = T))
dados_completos %>% summarise(sd(Concentration_uM, na.rm = T))
dados_completos %>% summarise(median(Concentration_uM, na.rm = T))
dados_completos %>% summarise(min(Concentration_uM, na.rm = T))
dados_completos %>% summarise(max(Concentration_uM, na.rm = T))
ggplot(dados_completos, aes(x=Concentration_uM)) +
geom_histogram(binwidth = 1, color="black", fill = "white") +
theme_classic() +
scale_y_continuous(n.breaks = 10) +
scale_x_continuous(n.breaks = 10)
dif = dados_completos %>% count(Diferentiation_method)
kable(dif %>% arrange(-n), digits = 1)
#adicionar meio de cultura, suplementos, soro e concentracao
experiment_level = data.frame(
Feature=c("Describes cell source",
"Describes cell authentication",
"Describes mycoplasma testing",
"Control group is clear",
"Describes Abeta sequence",
"Describes Abeta origin",
"Describes Abeta species",
"Describes Abeta aggregation",
"Has single exposure",
"Describes duration of Abeta exposure",
"Describes concentration of Abeta"),
Count = c(as.numeric(csource[2,2]+csource[1,2]),
as.numeric(cauthent[2,2]),
as.numeric(cmyco[2,2]),
as.numeric(control[3,2]),
sum(!is.na(dados_completos$Abeta_sequence)),
as.numeric(a_orig[3,2]),
as.numeric(a_spec[3,2]),
as.numeric(a_aggr[4,2]),
as.numeric(a_exp[2,2]),
sum(!is.na(dados_completos$Duration_hours)),
sum(!is.na(dados_completos$Concentration_uM))),
Percent = c(as.numeric(csource[2,2]+csource[1,2])*100/nrow(dados_completos),
as.numeric(cauthent[2,2])*100/nrow(dados_completos),
as.numeric(cmyco[2,2])*100/nrow(dados_completos),
as.numeric(control[3,2])*100/nrow(dados_completos),
sum(!is.na(dados_completos$Abeta_sequence))*100/nrow(dados_completos),
as.numeric(a_orig[3,2])*100/nrow(dados_completos),
as.numeric(a_spec[3,2])*100/nrow(dados_completos),
as.numeric(a_aggr[4,2])*100/nrow(dados_completos),
as.numeric(a_exp[2,2])*100/nrow(dados_completos),
sum(!is.na(dados_completos$Duration_hours))*100/nrow(dados_completos),
sum(!is.na(dados_completos$Concentration_uM))*100/nrow(dados_completos))
)
kable(experiment_level, digits = 1)
dados_completos1 = dados_limpos %>% filter(control_mean!=0&!is.na(control_mean)&treated_mean!=0&!is.na(treated_mean)&treated_variation!=0&!is.na(treated_variation))
dados_sem_n = dados_completos1 %>% filter(control_n==0&is.na(control_n)&treated_n==0&is.na(treated_n))
dados_sem_n = dados_completos1 %>% filter(control_n==0|is.na(control_n)|treated_n==0|is.na(treated_n))
1394-1199
writexl::write_xlsx(dados_sem_n, "dados_sem_n.xlsx")
